---
---

% ======================================================================
% ========================= Mes "publications"==========================
% ======================================================================
@inproceedings{le-etal-2024-analyzing,
    bibtex_show = {true},
    title = "Analyzing Byte-Pair Encoding on Monophonic and Polyphonic Symbolic Music: A Focus on Musical Phrase Segmentation",
    author = "Le, Dinh-Viet-Toan and Bigo, Louis and Keller, Mikaela",
    editor = "Kruspe, Anna and Oramas, Sergio and Epure, Elena V. and Sordo, Mohamed and Weck, Benno and Doh, SeungHeon and Won, Minz and Manco, Ilaria and Meseguer-Brocal, Gabriel",
    booktitle = "Proceedings of the 3rd Workshop on NLP for Music and Audio (NLP4MusA)",
    month = nov,
    year = "2024",
    address = "Oakland, USA",
    publisher = "Association for Computational Lingustics",
    url = "https://aclanthology.org/2024.nlp4musa-1.12/",
    pages = "69--74",
    abstract = "Byte-Pair Encoding (BPE) is an algorithm commonly used in Natural Language Processing to build a vocabulary of subwords, which has been recently applied to symbolic music. Given that symbolic music can differ significantly from text, particularly with polyphony, we investigate how BPE behaves with different types of musical content. This study provides a qualitative analysis of BPE`s behavior across various instrumentations and evaluates its impact on a musical phrase segmentation task for both monophonic and polyphonic music. Our findings show that the BPE training process is highly dependent on the instrumentation and that BPE {\textquotedblleft}supertokens{\textquotedblright} succeed in capturing abstract musical content. In a musical phrase segmentation task, BPE notably improves performance in a polyphonic setting, but enhances performance in monophonic tunes only within a specific range of BPE merges.",
    abbr        = {Symbolic<br>Music Analysis},
    pdf         = {https://aclanthology.org/2024.nlp4musa-1.12/},
    code        = {https://github.com/dinhviettoanle/musicbpe-mono-poly},
    preview     = {bpe.png}
}


@inproceedings{le2025evaluating,
  bibtex_show = {true},
  title       = {Evaluating Interval-based Tokenization for Pitch Representation in Symbolic Music Analysis},
  author      = {Le, Dinh-Viet-Toan and Bigo, Louis and Keller, Mikaela},
  year        = 2025,
  month       = Mar,
  booktitle   = {Workshop Artificial Intelligence for Music at AAAI},
  location    = {Philadelphia, United States},
  abbr        = {Symbolic<br>Music Analysis},
  preview     = {intervalization.png}
}

@misc{le2024meteor,
  bibtex_show   = {true},
  title         = {METEOR: Melody-aware Texture-controllable Symbolic Orchestral Music Generation},
  author        = {Dinh-Viet-Toan Le and Yi-Hsuan Yang},
  year          = {2024},
  month         = Sep,
  eprint        = {2409.11753},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SD},
  abbr          = {Symbolic<br>Music Generation},
  pdf           = {https://arxiv.org/abs/2409.11753},
  code          = {https://github.com/dinhviettoanle/meteor},
  demo          = {https://dinhviettoanle.github.io/meteor/},
  preview       = {meteor.png}
}


misc{le2024natural,
  bibtex_show   = {true},
  title         = {Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: A Survey},
  author        = {Dinh-Viet-Toan Le and Louis Bigo and Mikaela Keller and Dorien Herremans},
  year          = 2024,
  month         = Feb,
  eprint        = {2402.17467},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  abbr          = {Survey},
  pdf           = {https://arxiv.org/abs/2402.17467},
  code          = {https://github.com/dinhviettoanle/survey-music-nlp},
  preview       = {survey.png}
}


@article{le2025natural,
  bibtex_show = {true},
  author      = {Dinh-Viet-Toan Le and Louis Bigo and Mikaela Keller and Dorien Herremans},
  title       = {Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: A Survey},
  year        = {2025},
  issue_date  = {},
  publisher   = {Association for Computing Machinery},
  address     = {New York, NY, USA},
  volume      = {},
  number      = {},
  issn        = {},
  url         = {},
  doi         = {},
  abstract    = {Music is frequently associated with the notion of language as both domains share several similarities, including the ability for their content to be represented as sequences of symbols. In computer science, the fields of Natural Language Processing (NLP) and Music Information Retrieval (MIR) reflect this analogy through a variety of similar tasks, such as author detection or content generation. This similarity has long encouraged the adaptation of NLP methods to process musical data, in particular symbolic music data, and the rise of Transformer neural networks has considerably strengthened this practice. This survey reviews NLP methods applied to symbolic music generation and information retrieval following two axes. We first propose an overview of representations of symbolic music inspired by text sequential representations. We then review a large set of computational models, in particular deep learning models, that have been adapted from NLP to process these musical representations for various MIR tasks. These models are described and categorized through different prisms with a highlight on their music-specialized mechanisms. We finally present a discussion surrounding the adequate use of NLP tools to process symbolic music data. This includes technical issues regarding NLP methods which may open several doors for further research into more effectively adapting NLP tools to symbolic MIR.},
  journal     = {ACM Computing Surveys},
  month       = {},
  articleno   = {},
  numpages    = {},
  keywords    = {},
  abbr        = {Survey},
  pdf         = {https://arxiv.org/abs/2402.17467},
  code        = {https://github.com/dinhviettoanle/survey-music-nlp},
  preview     = {survey.png},
  note        = {[Accepted]}
}

@inproceedings{le2022orchestral,
  bibtex_show = {true},
  title       = {A Corpus Describing Orchestral Texture in First Movements of Classical and Early-Romantic Symphonies},
  author      = {Le, Dinh-Viet-Toan and Giraud, Mathieu and Lev\'{e}, Florence and Maccarini, Francesco},
  year        = 2022,
  month       = Jul,
  booktitle   = {Proceedings of the 9th International Conference on Digital Libraries for Musicology},
  pages       = {27-35},
  location    = {Prague, Czech Republic},
  publisher   = {Association for Computing Machinery},
  address     = {New York, NY, USA},
  isbn        = 9781450396684,
  url         = {https://doi.org/10.1145/3543882.3543884},
  doi         = {10.1145/3543882.3543884},
  abstract    = {Orchestration is the art of writing music for a possibly large ensemble of instruments, by blending or opposing their sounds and grouping them into an orchestral texture. We aim here at providing a deeper understanding of orchestration in classical and early-romantic symphonies by analyzing, at the bar level, how the instruments of the orchestra organize into melodic, rhythmic, harmonic, and mixed layers. We formalize the description of such layers and release an open corpus with more than 7900&nbsp;annotations in 24&nbsp;first movements of Haydn, Mozart, and Beethoven symphonies. Initial analyses of this corpus confirm specific roles of the instruments and their families (woodwinds, brass, and strings), some evolution between composers, as well as the contribution of orchestral texture to form. The model and the corpus offer perspectives for empirical and computational studies on orchestral music.},
  numpages    = 9,
  keywords    = {corpus, layers, music texture, orchestration, symbolic data},
  series      = {DLfM '22},
  abbr        = {Musicology},
  pdf         = {https://hal.science/hal-03663112/document},
  code        = {https://gitlab.com/algomus.fr/orchestration},
  preview     = {orchestral_texture.png}
}